
# Q1: 如何设计一个高并发高可用的系统?
》做一个千万级的秒杀系统
设计过程：中间遇到哪些问题，如何解决
不能超卖，不能漏卖

## 明确问题和应用场景
目标是：

## 系统架构设计
设计理念：层层过滤，化峰为谷
核心思想是将千万级的瞬时请求，通过一系列手段进行过滤和分流，最终只有与库存数量相当的有效请求能够到达最后的数据库层面，从而保护系统的稳定性和数据一致性。整个用户请求流程就像一个巨大的漏斗。

设计过程与挑战解决方案

### 第一阶段：前端与CDN层 (过滤90%的无效请求)**

这是用户请求的第一站，也是整个漏斗最宽的入口。

遇到的问题1：页面加载风暴。
在秒杀开始的瞬间，数千万用户同时刷新页面，请求HTML/CSS/JS/图片等静态资源，这会直接打垮我们的应用服务器集群。

解决方案：

- 静态资源CDN化：将所有可静态化的资源（页面、图片、脚本）全部部署到CDN（内容分发网络）上。CDN节点遍布全国，用户可以就近访问，这不仅大大加快了加载速度，也使得90%以上的静态请求根本不会到达我们的源站。

- 动态页面静态化：将秒杀页面的主体内容，如商品描述、图片等，提前渲染成一个静态HTML文件，同样部署到CDN。页面中的动态信息（如服务器时间、库存状态）通过独立的JS脚本异步加载。

遇到的问题2：无效的“秒杀”按钮点击。
秒杀开始前，用户会疯狂点击那个置灰的按钮；秒杀结束后，用户也会继续点击。这些都是无效请求。

解决方案：

按钮置灰与客户端控制：秒杀开始前，按钮为灰色，点击无效。通过前端JS定时向服务器请求时间，进行倒计时。当客户端时间到达秒杀时间点后，按钮才点亮。这可以过滤掉大部分“提前”的请求。

请求唯一性：用户点击秒杀按钮后，无论请求成功与否，按钮应立即置灰，并显示“处理中...”或“已售罄”，防止用户因紧张或网络延迟而重复提交请求。

### **第二阶段：网关与负载均衡层 (过滤恶意请求与分流)**
请求穿透CDN后，会到达我们系统的入口——API网关。

遇到的问题：DDoS攻击、黄牛刷接口、瞬时流量不均。
黑产和黄牛会使用大量机器模拟用户行为，以极高的频率直接调用秒杀接口。同时，瞬时流量可能导致部分服务器过载，而另一些服务器空闲。

解决方案：

多级网关限流架构
L4 负载均衡: 部署在网络边缘，直接面向公网，处理的是最原始的 TCP/IP流量，性能高，但只识别 四层传输层协议
	-  负责负载均衡，使用 Direct Routing 模式的 LVS，通过修改 MAC 地址直接将网络包转发给后端网关集群，性能极高
	-   IP 黑名单：对于已知的攻击源 IP，L4 可以直接丢弃 TCP 连接请求，可以将大量恶意流量在最外层就拦截掉
L7 网关集群 Ngnix: 流量经过 L4 LB 分发之后，到达这一层的某个网关实例，这一层可以识别 HTTP 协议，可以做更精细化的处理。
	-   基于 IP 的限流：网关层可以获取到客户端真实 IP（由 L4 LB 通过 PROXY 协议等方式透传）。基于 IP 的限流廉价效果好，通过查询分布式缓存中的技术器，可以有效防止单一 IP 的恶意攻击。
	-   基础的路由和 TLS 卸载：根据请求的域名或者 URL 匹配规则，将请求路由到不同的业务集群。同时 SSL/TLS 的加解密工作通常也在这一层完成。
	
业务网关（中心式或者 Mesh 部署模式）:
业务中常见的用户鉴权，会话，协议转换等可以在这一层完成，更推荐使用 Mesh agent 方式靠近服务进程。


### 第三阶段：服务层 (核心业务逻辑与库存预扣减)
这是秒杀系统的核心，也是保证“不可超卖”的第一道防线。

遇到的问题1：数据库成为性能瓶瓶颈。
这是最核心的问题。如果千万级请求直接打到数据库上执行 
`UPDATE product SET stock = stock - 1 WHERE product_id = 1 AND stock > 0`，数据库会因大量的行锁竞争和连接数耗尽而瞬间崩溃。

**解决方案**：将库存从数据库剥离，前置到分布式缓存中。

1. Redis原子操作：在秒杀开始前，将商品库存预加载到Redis中。例如 `SET product:123:stock 1000`。

2. 利用Redis的单线程和原子性：扣减库存的操作不读数据库，而是直接在Redis中执行。最经典的方案是使用Lua脚本，保证“读-改-写”的原子性。

```lua

-- Redis Lua Script for Atomic Inventory Deduction
local stock_key = KEYS[1]       -- 商品库存键
local user_key = KEYS[2]        -- 用户已购记录键
local user_id = ARGV[1]         -- 用户ID

-- 检查用户是否已购买过
if redis.call('sismember', user_key, user_id) == 1 then
    return 2 -- 2: 重复购买
end

-- 检查库存
local stock = tonumber(redis.call('get', stock_key))
if stock and stock > 0 then
    redis.call('decr', stock_key)
    redis.call('sadd', user_key, user_id)
    return 1 -- 1: 成功
else
    return 0 -- 0: 库存不足
end
```
通过执行这个Lua脚本，Redis能原子性地完成“检查库存 -> 扣减库存 -> 记录购买用户”这一系列操作，完美地避免了并发场景下的超卖问题。因为Redis的单机QPS可以达到10万级别，通过集群分片，理论上可以水平扩展以应对更高的并发。

**遇到的问题2：如何筛选出“中奖”用户？**
即使有Redis，让所有请求都去执行Lua脚本也是一种浪费。我们需要进一步过滤。

**解决方案：库存令牌桶/队列**
在Redis中，除了库存数，还可以额外设置一个List或Set作为“令牌池”，里面预先放入与库存等量的令牌。

用户请求先执行 LPOP 或 SPOP 从令牌池获取令牌。

获取到令牌的请求，才有资格去执行后续的Lua脚本扣减真实库存。

获取不到令牌的请求，直接返回“已售罄”，无需再访问库存键。
这进一步减轻了对单个库存Key的激烈竞争。

#### 存在的问题
1. 为了应对水平扩展提升性能 & 高可用，避免单点故障问题，Redis 会使用集群模式，那么如何保障 Redis 的数据不丢 & 数据一致：
题一：如何保证 Redis 中的数据不丢？
在 Redis Cluster 模式下，"数据不丢"的目标是通过一个多层次的防御体系来实现的，它能应对从单节点故障到整个集群断电的多种场景。

1. 高可用机制：主从复制与自动故障转移
这是防止因单个节点硬件或软件故障导致数据丢失的第一道防线。

主从复制 (Replication)：在集群的每个分片（Shard）内部，都配置为一主多从（至少一主一从）的结构。Master 节点负责处理写请求，并异步地将数据变更同步给 Slave 节点。

自动故障转移 (Failover)：集群内置了类似 Sentinel 的故障发现和转移机制。当一个 Master 节点被集群中的大多数 Master 节点认为下线时，它的 Slave 节点会发起选举，获胜的 Slave 会被提升为新的 Master，接管分片的读写流量。

保障效果：这个机制可以保证在 99.9% 的单点故障场景下，数据几乎不丢失（可能丢失最后一秒内、尚未完成异步复制的数据），并且服务可以秒级恢复。

2. 数据持久化机制：RDB 与 AOF
这是应对集群整体断电、所有节点都需要重启等灾难性场景的最后一道防线。

RDB (快照)：将某一时刻 Redis 内存中的数据完整地保存到磁盘上的一个二进制文件中。你可以配置策略，如“每5分钟且至少有100次写入时，执行一次快照”。

优点：文件紧凑，恢复速度快。

缺点：两次快照之间的数据会全部丢失。

AOF (Append-Only File)：将每一条执行的写命令追加到文件末尾。当 Redis 重启时，会重新执行 AOF 文件中的所有命令来恢复数据。AOF 的同步策略有三种：always (每条命令都同步)、everysec (每秒同步一次)、no (由操作系统决定)。

优点：数据最不容易丢失（everysec 策略下最多丢失1秒的数据）。

缺点：文件体积大，恢复速度通常慢于 RDB。

最佳实践：
在生产环境中，通常会同时开启 RDB 和 AOF。

使用 AOF 的 everysec 策略作为主要的数据保障，最大限度减少数据损失。

使用 RDB 作为数据备份和快速恢复的补充。当 Redis 重启时，如果同时存在 AOF 和 RDB 文件，它会优先使用 AOF 文件进行恢复，因为它能保证数据最完整。

3. 内存管理策略：避免数据被动淘汰 (Eviction)
当 Redis 的内存使用达到 maxmemory 上限时，会触发数据淘汰策略。如果策略设置不当，可能会把我们预热的关键数据给“挤掉”。

关键配置：对于预热的、绝不能丢失的关键数据（如秒杀的商品信息、库存），单独设置 Redis 集群，Redis 的淘汰策略 maxmemory-policy 应该设置为 noeviction。

效果：当内存满时，任何试图写入新数据的命令都会直接报错，而不是删除旧数据。这会让问题显式地暴露出来（例如通过告警），而不是静默地丢失数据。它强迫我们必须为 Redis 规划足够的内存，或者清理不再需要的数据。

总结：通过 主从复制 + 自动故障转移 来应对节点故障，通过 AOF + RDB 持久化 来应对灾难性故障，再通过 noeviction 内存策略 来防止数据被动丢失，我们构建了一个完整的体系来确保 Redis 中的数据安全。

问题二：如何保证 Redis 与数据库中的数据一致？
这是一个经典的分布式系统难题，没有一劳永逸的“银弹”方案，必须根据业务场景选择合适的策略。

阶段一：预热阶段的一致性
在秒杀活动开始前，我们需要将数据库中的商品和库存数据加载到 Redis 中。

更先进的方案是使用 CDC (Change Data Capture) 工具，如 Canal，它通过伪装成一个 MySQL 的 Slave 来监听 binlog，实时地捕捉数据变更并推送到 MQ 或直接写入 Redis，实现准实时同步。

阶段二：运行阶段的一致性（秒杀进行时）
这是最关键的阶段。传统的“缓存-数据库”一致性方案（如 Cache-Aside、Read/Write Through）在秒杀场景下都过于复杂且性能低下。

秒杀场景的特定策略：反转数据源，以 Redis 为准

在秒杀的这个特定时间窗口内，我们不再追求 Redis 和数据库的强一致性，而是采用一种颠覆性的策略：

信任 Redis：在秒杀开始到结束的这几分钟内，Redis 中的库存就是唯一被信任的库存。所有的库存扣减操作 只在 Redis 中进行。数据库在此时的角色从“事实的数据源”降级为“最终的备份存储”。

异步写回：当用户在 Redis 中成功扣减库存后（参考之前提到的Lua脚本方案），系统会生成一条包含订单信息的消息，并将其发送到高可靠的**消息队列（MQ）**中。

最终一致性：下游的订单处理服务会从 MQ 中消费这些消息，然后才去创建订单并扣减数据库中的库存。这个过程是异步的，允许有一定的延迟。

对账与补偿：秒杀结束后，运行一个对账程序，比对 Redis 的最终库存扣减量和数据库中生成的订单量，确保两者一致。如果不一致，需要有补偿机制来修正数据。

为什么这种模式是最佳的？

性能极致：所有读写压力都由高性能的 Redis 集群承载，完全绕开了慢速的、带事务的数据库，这是能够支撑千万级 QPS 的根本。

避免复杂性：它巧妙地规避了所有复杂的双写一致性、缓存失效等问题。在关键的时间窗口内，我们只相信一个数据源，大大简化了系统设计。

业务可接受：对于秒杀业务而言，用户只关心自己是否“抢到”，而不在乎后台的数据库库存是否是毫秒级同步的。最终一致性是完全可以接受的。

总结：
保证 Redis 与数据库一致性的问题，在秒杀场景下被巧妙地划分为两个阶段：

预热阶段：通过“CDC”等方式，保证 Redis 拥有一个准确的初始数据快照。

运行阶段：通过反转数据源的策略，以 Redis 为准，通过 MQ 实现对数据库的最终一致性。这是一种用架构设计来解决复杂技术问题的典型思路。


### 第四阶段：异步下单与持久化
成功在Redis中抢到资格的用户，需要生成真实的订单并写入数据库。

遇到的问题：同步写库导致用户体验差和系统雪崩。
创建订单是一个复杂的业务逻辑，可能涉及写入订单表、订单详情表、扣减优惠券、生成物流信息等，这是一个慢操作。如果在秒杀接口中同步执行，会导致请求的响应时间极长，并且大量的数据库写入操作依旧会形成瓶颈，拖垮整个系统。

解决方案：使用消息队列（MQ）进行异步解耦。

发送消息：在Redis中成功扣减库存后，服务层并不立即创建订单，而是生成一条包含userId和productId的订单消息，并将其发送到高可靠的消息队列（如Kafka, RocketMQ）中。

快速响应：消息一旦成功发送到MQ，就可以立即向用户返回“秒杀成功，订单处理中”的友好提示，此时用户的请求已经完成，整个前端体验非常流畅。

异步消费：下游有一个专门的“订单服务”集群，它们会以自己能处理的速度，平稳地从MQ中拉取消息，然后慢慢地、一个一个地创建订单，完成数据库的持久化操作。

这种“化峰为谷”的设计，将秒杀瞬间的写数据库洪峰，削平为一段时间内平稳的流量，彻底解决了数据库的写入瓶颈。
> 对前端来说，类似于弹出抢购成功，然后跳转支付界面，这个时候查询并等待订单创建成功

遇到的问题：如何保证“不可少卖”？
如果用户抢到了资格（Redis库存已减），但后续的订单创建过程失败了（例如，消费者服务宕机），就会出现“少卖”的情况。

解决方案：

高可靠MQ：选择支持持久化和ACK（确认）机制的MQ。消费者在成功创建订单并写入数据库后，才向MQ发送ACK，MQ才会将该消息标记为已消费。如果消费者异常退出，未被ACK的消息会在一段时间后被重新投递给其他消费者。

订单对账：在秒杀结束后，需要有一个后台对账系统。它会比对Redis中的成功记录数和数据库中最终生成的订单数。如果发现不一致，可以进行数据修复或人工介入，确保每一笔成功的秒杀都有对应的订单。

支付超时与库存返还：创建订单后，用户有15分钟的支付时间。需要一个定时任务扫描未支付的超时订单，将其关闭，并原子性地将库存加回到Redis中，以便进行下一轮销售。

## 最终架构总结
客户端：本地倒计时、按钮控制，减少无效请求。

CDN：承载90%的静态资源流量。

负载均衡/API网关：DDoS防护、IP/UID限流。

无状态应用集群：水平扩展，处理业务逻辑。

分布式缓存（Redis集群）：作为库存的“事实权威”，通过Lua脚本保证原子性扣减，解决超卖问题。

消息队列（Kafka/RocketMQ）：异步解耦下单流程，削平数据库写入洪峰。

消费者集群：平稳地处理订单创建，持久化到数据库。

数据库（分库分表）：作为最终数据一致性的存储，通过异步化避免了成为瓶颈。

通过这样一套环环相扣、层层过滤的体系，才有可能在理论上支撑起千万级QPS的秒杀场景，同时严格保证数据的一致性和业务的正确性。每一步都是为了将压力留在系统的更外层，保护最脆弱的核心数据层。




	
# Q2: LLM 应用
	- Prompt 调优
	- Agent 动态决策，MCP 使用外部功能
	- RAG 外挂知识库，Oncall 机器人
	- Workflow 工作流
	- 文生图、
	Q2.1 Prompt 调优方法论：
	Q2.2 如何做好一个 RAG，怎么样让 RAG 更准确召回
	   - 分片
	   - 召回相似性

	Q2.3 Manus ❌
# Q3: 事务机制，隔离级别，如何实现事务；
	什么是事务，ACID
	RU, RC, RR, SR
	间隙锁，和记录锁的区别，使用场景
	
# 算法题：


# QA