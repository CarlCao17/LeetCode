
# Q1: 如何设计一个高并发高可用的系统?
》做一个千万级的秒杀系统
设计过程：中间遇到哪些问题，如何解决
不能超卖，不能漏卖

## 明确问题和应用场景
目标是：

## 系统架构设计
设计理念：层层过滤，化峰为谷
核心思想是将千万级的瞬时请求，通过一系列手段进行过滤和分流，最终只有与库存数量相当的有效请求能够到达最后的数据库层面，从而保护系统的稳定性和数据一致性。整个用户请求流程就像一个巨大的漏斗。

设计过程与挑战解决方案

### 第一阶段：前端与CDN层 (过滤90%的无效请求)**

这是用户请求的第一站，也是整个漏斗最宽的入口。

遇到的问题1：页面加载风暴。
在秒杀开始的瞬间，数千万用户同时刷新页面，请求HTML/CSS/JS/图片等静态资源，这会直接打垮我们的应用服务器集群。

解决方案：

- 静态资源CDN化：将所有可静态化的资源（页面、图片、脚本）全部部署到CDN（内容分发网络）上。CDN节点遍布全国，用户可以就近访问，这不仅大大加快了加载速度，也使得90%以上的静态请求根本不会到达我们的源站。

- 动态页面静态化：将秒杀页面的主体内容，如商品描述、图片等，提前渲染成一个静态HTML文件，同样部署到CDN。页面中的动态信息（如服务器时间、库存状态）通过独立的JS脚本异步加载。

遇到的问题2：无效的“秒杀”按钮点击。
秒杀开始前，用户会疯狂点击那个置灰的按钮；秒杀结束后，用户也会继续点击。这些都是无效请求。

解决方案：

按钮置灰与客户端控制：秒杀开始前，按钮为灰色，点击无效。通过前端JS定时向服务器请求时间，进行倒计时。当客户端时间到达秒杀时间点后，按钮才点亮。这可以过滤掉大部分“提前”的请求。

请求唯一性：用户点击秒杀按钮后，无论请求成功与否，按钮应立即置灰，并显示“处理中...”或“已售罄”，防止用户因紧张或网络延迟而重复提交请求。

### **第二阶段：网关与负载均衡层 (过滤恶意请求与分流)**
请求穿透CDN后，会到达我们系统的入口——API网关。

遇到的问题：DDoS攻击、黄牛刷接口、瞬时流量不均。
黑产和黄牛会使用大量机器模拟用户行为，以极高的频率直接调用秒杀接口。同时，瞬时流量可能导致部分服务器过载，而另一些服务器空闲。

解决方案：

多级网关限流架构
L4 负载均衡: 部署在网络边缘，直接面向公网，处理的是最原始的 TCP/IP流量，性能高，但只识别 四层传输层协议
	-  负责负载均衡，使用 Direct Routing 模式的 LVS，通过修改 MAC 地址直接将网络包转发给后端网关集群，性能极高
	-   IP 黑名单：对于已知的攻击源 IP，L4 可以直接丢弃 TCP 连接请求，可以将大量恶意流量在最外层就拦截掉
L7 网关集群 Ngnix: 流量经过 L4 LB 分发之后，到达这一层的某个网关实例，这一层可以识别 HTTP 协议，可以做更精细化的处理。
	-   基于 IP 的限流：网关层可以获取到客户端真实 IP（由 L4 LB 通过 PROXY 协议等方式透传）。基于 IP 的限流廉价效果好，通过查询分布式缓存中的技术器，可以有效防止单一 IP 的恶意攻击。
	-   基础的路由和 TLS 卸载：根据请求的域名或者 URL 匹配规则，将请求路由到不同的业务集群。同时 SSL/TLS 的加解密工作通常也在这一层完成。
	
业务网关（中心式或者 Mesh 部署模式）:
业务中常见的用户鉴权，会话，协议转换，自定义限流、部分地区不可用等可以在这一层完成，更推荐使用 Mesh agent 方式靠近服务进程。


### 第三阶段：服务层 (核心业务逻辑与库存预扣减)
这是秒杀系统的核心，也是保证“不可超卖”的第一道防线。

遇到的问题1：数据库成为性能瓶瓶颈。
这是最核心的问题。如果千万级请求直接打到数据库上执行 
`UPDATE product SET stock = stock - 1 WHERE product_id = 1 AND stock > 0`，数据库会因大量的行锁竞争和连接数耗尽而瞬间崩溃。

**解决方案**：将库存从数据库剥离，前置到分布式缓存中。

1. Redis原子操作：在秒杀开始前，将商品库存预加载到Redis中。例如 `SET product:123:stock 1000`。

2. 利用Redis的单线程和原子性：扣减库存的操作不读数据库，而是直接在Redis中执行。最经典的方案是使用Lua脚本，保证“读-改-写”的原子性。

```lua

-- Redis Lua Script for Atomic Inventory Deduction
local stock_key = KEYS[1]       -- 商品库存键
local user_key = KEYS[2]        -- 用户已购记录键
local user_id = ARGV[1]         -- 用户ID

-- 检查用户是否已购买过
if redis.call('sismember', user_key, user_id) == 1 then
    return 2 -- 2: 重复购买
end

-- 检查库存
local stock = tonumber(redis.call('get', stock_key))
if stock and stock > 0 then
    redis.call('decr', stock_key)
    redis.call('sadd', user_key, user_id)
    return 1 -- 1: 成功
else
    return 0 -- 0: 库存不足
end
```
通过执行这个Lua脚本，Redis能原子性地完成“检查库存 -> 扣减库存 -> 记录购买用户”这一系列操作，完美地避免了并发场景下的超卖问题。因为Redis的单机QPS可以达到10万级别，通过集群分片，理论上可以水平扩展以应对更高的并发。

**遇到的问题2：如何筛选出“中奖”用户？**
即使有Redis，让所有请求都去执行Lua脚本也是一种浪费。我们需要进一步过滤。

**解决方案：库存令牌桶/队列**
在Redis中，除了库存数，还可以额外设置一个List或Set作为“令牌池”，里面预先放入与库存等量的令牌。

用户请求先执行 LPOP 或 SPOP 从令牌池获取令牌。

获取到令牌的请求，才有资格去执行后续的Lua脚本扣减真实库存。

获取不到令牌的请求，直接返回“已售罄”，无需再访问库存键。
这进一步减轻了对单个库存Key的激烈竞争。

#### 存在的问题
1. 为了应对水平扩展提升性能 & 高可用，避免单点故障问题，Redis 会使用集群模式，那么如何保障 Redis 的数据不丢 & 数据一致：
题一：如何保证 Redis 中的数据不丢？
在 Redis Cluster 模式下，"数据不丢"的目标是通过一个多层次的防御体系来实现的，它能应对从单节点故障到整个集群断电的多种场景。

1. 高可用机制：主从复制与自动故障转移
这是防止因单个节点硬件或软件故障导致数据丢失的第一道防线。

主从复制 (Replication)：在集群的每个分片（Shard）内部，都配置为一主多从（至少一主一从）的结构。Master 节点负责处理写请求，并异步地将数据变更同步给 Slave 节点。

自动故障转移 (Failover)：集群内置了类似 Sentinel 的故障发现和转移机制。当一个 Master 节点被集群中的大多数 Master 节点认为下线时，它的 Slave 节点会发起选举，获胜的 Slave 会被提升为新的 Master，接管分片的读写流量。

保障效果：这个机制可以保证在 99.9% 的单点故障场景下，数据几乎不丢失（可能丢失最后一秒内、尚未完成异步复制的数据），并且服务可以秒级恢复。

2. 数据持久化机制：RDB 与 AOF
这是应对集群整体断电、所有节点都需要重启等灾难性场景的最后一道防线。

RDB (快照)：将某一时刻 Redis 内存中的数据完整地保存到磁盘上的一个二进制文件中。你可以配置策略，如“每5分钟且至少有100次写入时，执行一次快照”。

优点：文件紧凑，恢复速度快。

缺点：两次快照之间的数据会全部丢失。

AOF (Append-Only File)：将每一条执行的写命令追加到文件末尾。当 Redis 重启时，会重新执行 AOF 文件中的所有命令来恢复数据。AOF 的同步策略有三种：always (每条命令都同步)、everysec (每秒同步一次)、no (由操作系统决定)。

优点：数据最不容易丢失（everysec 策略下最多丢失1秒的数据）。

缺点：文件体积大，恢复速度通常慢于 RDB。

最佳实践：
在生产环境中，通常会同时开启 RDB 和 AOF。

使用 AOF 的 everysec 策略作为主要的数据保障，最大限度减少数据损失。

使用 RDB 作为数据备份和快速恢复的补充。当 Redis 重启时，如果同时存在 AOF 和 RDB 文件，它会优先使用 AOF 文件进行恢复，因为它能保证数据最完整。

3. 内存管理策略：避免数据被动淘汰 (Eviction)
当 Redis 的内存使用达到 maxmemory 上限时，会触发数据淘汰策略。如果策略设置不当，可能会把我们预热的关键数据给“挤掉”。

关键配置：对于预热的、绝不能丢失的关键数据（如秒杀的商品信息、库存），单独设置 Redis 集群，Redis 的淘汰策略 maxmemory-policy 应该设置为 noeviction。

效果：当内存满时，任何试图写入新数据的命令都会直接报错，而不是删除旧数据。这会让问题显式地暴露出来（例如通过告警），而不是静默地丢失数据。它强迫我们必须为 Redis 规划足够的内存，或者清理不再需要的数据。

总结：通过 主从复制 + 自动故障转移 来应对节点故障，通过 AOF + RDB 持久化 来应对灾难性故障，再通过 noeviction 内存策略 来防止数据被动丢失，我们构建了一个完整的体系来确保 Redis 中的数据安全。

问题二：如何保证 Redis 与数据库中的数据一致？
这是一个经典的分布式系统难题，没有一劳永逸的“银弹”方案，必须根据业务场景选择合适的策略。

阶段一：预热阶段的一致性
在秒杀活动开始前，我们需要将数据库中的商品和库存数据加载到 Redis 中。

1. 提前一段时间，我们将库存写入到 Redis 中

// 更先进的方案是使用 CDC (Change Data Capture) 工具，通过伪装成一个 MySQL 的 Slave 来监听 binlog，实时地捕捉数据变更并推送到 MQ 或直接写入 Redis，实现准实时同步。

阶段二：运行阶段的一致性（秒杀进行时）
这是最关键的阶段。传统的“缓存-数据库”一致性方案（如 Cache-Aside、Read/Write Through）在秒杀场景下都过于复杂且性能低下。

秒杀场景的特定策略：反转数据源，以 Redis 为准

在秒杀的这个特定时间窗口内，我们不再追求 Redis 和数据库的强一致性，而是采用一种颠覆性的策略：

信任 Redis：在秒杀开始到结束的这几分钟内，Redis 中的库存就是唯一被信任的库存。所有的库存扣减操作 只在 Redis 中进行。数据库在此时的角色从“事实的数据源”降级为“最终的备份存储”。

异步写回：当用户在 Redis 中成功扣减库存后（参考之前提到的Lua脚本方案），系统会生成一条包含订单信息的消息，并将其发送到高可靠的**消息队列（MQ）**中。

最终一致性：下游的订单处理服务会从 MQ 中消费这些消息，然后才去创建订单并扣减数据库中的库存。这个过程是异步的，允许有一定的延迟。

对账与补偿：秒杀结束后，运行一个对账程序，比对 Redis 的最终库存扣减量和数据库中生成的订单量，确保两者一致。如果不一致，需要有补偿机制来修正数据。

为什么这种模式是最佳的？

性能极致：所有读写压力都由高性能的 Redis 集群承载，完全绕开了慢速的、带事务的数据库，这是能够支撑千万级 QPS 的根本。

避免复杂性：它巧妙地规避了所有复杂的双写一致性、缓存失效等问题。在关键的时间窗口内，我们只相信一个数据源，大大简化了系统设计。

业务可接受：对于秒杀业务而言，用户只关心自己是否“抢到”，而不在乎后台的数据库库存是否是毫秒级同步的。最终一致性是完全可以接受的。

总结：
保证 Redis 与数据库一致性的问题，在秒杀场景下被巧妙地划分为两个阶段：

预热阶段：通过“CDC”等方式，保证 Redis 拥有一个准确的初始数据快照。

运行阶段：通过反转数据源的策略，以 Redis 为准，通过 MQ 实现对数据库的最终一致性。这是一种用架构设计来解决复杂技术问题的典型思路。


### 第四阶段：异步下单与持久化
成功在Redis中抢到资格的用户，需要生成真实的订单并写入数据库。

遇到的问题：同步写库导致用户体验差和系统雪崩。
创建订单是一个复杂的业务逻辑，可能涉及写入订单表、订单详情表、扣减优惠券、生成物流信息等，这是一个慢操作。如果在秒杀接口中同步执行，会导致请求的响应时间极长，并且大量的数据库写入操作依旧会形成瓶颈，拖垮整个系统。

解决方案：使用消息队列（MQ）进行异步解耦。

发送消息：在Redis中成功扣减库存后，服务层并不立即创建订单，而是生成一条包含userId和productId的订单消息，并将其发送到高可靠的消息队列（如Kafka, RocketMQ）中。

快速响应：消息一旦成功发送到MQ，就可以立即向用户返回“秒杀成功，订单处理中”的友好提示，此时用户的请求已经完成，整个前端体验非常流畅。

异步消费：下游有一个专门的“订单服务”集群，它们会以自己能处理的速度，平稳地从MQ中拉取消息，然后慢慢地、一个一个地创建订单，完成数据库的持久化操作。

这种“化峰为谷”的设计，将秒杀瞬间的写数据库洪峰，削平为一段时间内平稳的流量，彻底解决了数据库的写入瓶颈。
> 对前端来说，类似于弹出抢购成功，然后跳转支付界面，这个时候查询并等待订单创建成功

遇到的问题：如何保证“不可少卖”？
如果用户抢到了资格（Redis库存已减），但后续的订单创建过程失败了（例如，消费者服务宕机），就会出现“少卖”的情况。

解决方案：

高可靠MQ：选择支持持久化和ACK（确认）机制的MQ。消费者在成功创建订单并写入数据库后，才向MQ发送ACK，MQ才会将该消息标记为已消费。如果消费者异常退出，未被ACK的消息会在一段时间后被重新投递给其他消费者。

订单对账：在秒杀结束后，需要有一个后台对账系统。它会比对Redis中的成功记录数和数据库中最终生成的订单数。如果发现不一致，可以进行数据修复或人工介入，确保每一笔成功的秒杀都有对应的订单。

支付超时与库存返还：创建订单后，用户有15分钟的支付时间。需要一个定时任务扫描未支付的超时订单，将其关闭，并原子性地将库存加回到Redis中，以便进行下一轮销售。

## 最终架构总结
客户端：本地倒计时、按钮控制，减少无效请求。

CDN：承载90%的静态资源流量。

负载均衡/API网关：DDoS防护、IP/UID限流。

无状态应用集群：水平扩展，处理业务逻辑。

分布式缓存（Redis集群）：作为库存的“事实权威”，通过Lua脚本保证原子性扣减，解决超卖问题。

消息队列（Kafka/RocketMQ）：异步解耦下单流程，削平数据库写入洪峰。

消费者集群：平稳地处理订单创建，持久化到数据库。

数据库（分库分表）：作为最终数据一致性的存储，通过异步化避免了成为瓶颈。

通过这样一套环环相扣、层层过滤的体系，才有可能在理论上支撑起千万级QPS的秒杀场景，同时严格保证数据的一致性和业务的正确性。每一步都是为了将压力留在系统的更外层，保护最脆弱的核心数据层。

### 最终拓展
当前方式如果在秒杀活动越来越多，或者流量越来越大的情况下，比如双十一活动，因为集中式架构，全国、全球各地用户都访问中心机房造成的单点故障或者吞吐、性能不够。

那么这个时候，考虑建设异地多机房，通过将秒杀活动按照 adv_id 维度打散到多个机房，让多个机房共同承担活动流量，同时让业务逻辑完全单元化。
实现吞吐的多倍放大，稳定性提升且提升了系统的可用性，一旦出现灾备场景可以直接切换。

为了提升用户速度：网络架构需要改进，租用足够多的 CDN & 接入层，让公网尽可能贴近用户，然后走内部高速专线抵达 L4 LB。


	
# Q2: LLM 应用
	- Prompt 调优
	- Agent 动态决策，MCP 使用外部功能
	- RAG 外挂知识库，Oncall 机器人
	- Workflow 工作流
	- 文生图、
	Q2.1 Prompt 调优方法论
Prompt 调优（或称提示工程，Prompt Engineering）绝不是简单的“换个说法试试”，它是一门结合了语言学、认知心理学和计算机科学的实验性学科。一个好的方法论能将“碰运气”变为“可复制的优化过程”。

核心理念：将 Prompt 调优视为一个标准的迭代式开发周期（Iterative Development Cycle）。

第一步：明确目标与约束 (Define Goal & Constraints)
这是所有工作的基础。在写下第一个字之前，必须清晰地回答：

目标 (Goal)：我希望 LLM 输出什么？是代码、摘要、JSON 对象，还是角色扮演的对话？输出内容的格式、长度、语言、风格是怎样的？

约束 (Constraints)：LLM 不应该做什么？例如，不应泄露个人信息、不应编造事实（对于知识问答）、不应输出不安全的内容、输出必须少于200字等。

评估标准 (Evaluation Criteria)：我如何判断一个输出是“好”还是“坏”？是看事实准确性、格式正确性，还是用户满意度？

第二步：构建基准提示 (Build a Baseline Prompt - "V0")
从最简单、最直接的指令开始，这被称为 Zero-Shot Prompt。不要一开始就堆砌复杂的技巧。

示例："请总结以下文章：<文章内容>"

目的：建立一个性能基准。后续所有的优化都将与这个 V0 版本进行对比，以量化提升效果。

第三步：创建黄金评估集 (Create an Evaluation Set)
这是方法论中最关键、也最容易被忽略的一步。你无法改进你无法衡量的东西。

内容：准备一个包含 10-50 个典型输入样本的集合。这些样本应覆盖各种预期场景和边界情况。

标准答案：为评估集中的每个样本，都准备一个或多个理想的“黄金”输出。

作用：在每次修改 Prompt 后，用这个评估集进行自动化或半自动化的测试，快速判断新版 Prompt 的性能是提升了、下降了，还是在某些方面有得有失。

第四步：迭代优化与分析 (Iterate, Analyze & Refine)
这是 Prompt 调优的核心循环。基于对评估结果的分析，使用下面“工具箱”中的技巧来系统性地改进 Prompt。

Prompt 优化技巧工具箱（从基础到高级）：

明确性与细节 (Clarity & Specificity)

角色扮演 (Role-Playing)：赋予 LLM 一个专家角色。"你是一位资深的软件架构师..."

使用分隔符 (Use Delimiters)：使用 `"""、---、<tag>` 等清晰地分离指令、上下文、示例和用户输入，避免歧义。

明确指令动词 (Clear Action Verbs)：用“总结”、“提取”、“分类”、“重写”等精确动词代替模糊的“关于这个...”

指定输出格式 (Specify Output Format)：强制要求输出为 JSON、Markdown 列表、YAML 等，并给出格式示例。

提供上下文与示例 (Provide Context & Examples)

少样本提示 (Few-Shot Learning)：在 Prompt 中给出 1-5 个“输入-输出”的完整示例。这是提升模型表现最有效的方法之一，能让 LLM 快速理解你的意图和格式要求。

提供优质上下文 (Provide Quality Context)：对于需要外部知识的任务（RAG 的基础），确保提供的上下文是精准且相关的。

引导思维过程 (Guide the Thinking Process)

思维链 (Chain-of-Thought, CoT)：这是提升复杂推理任务性能的革命性技巧。要求 LLM 在给出最终答案前，先“一步一步地思考”或“展示其推理过程”。

示例："问题：... 在给出答案前，请逐步分析问题，列出你的推理步骤。"

原理：它迫使模型从一个快速、直觉式的回答（System 1 thinking）转变为一个缓慢、逻辑严密的推理过程（System 2 thinking），大大提高了复杂问题的准确率。

自我一致性 (Self-Consistency)：CoT 的进阶版。让模型用不同的推理路径多次回答同一个问题，然后选择票数最多的答案作为最终答案。这是一种集成学习（Ensemble）思想的应用。

高级策略

ReAct (Reason + Act)：允许 LLM 调用外部工具（如搜索引擎、计算器、API）来获取额外信息，然后结合新信息进行推理，循环往复直至问题解决。

通过 “定义 -> 基准 -> 评估 -> 迭代” 这个闭环，结合技巧工具箱，就可以将 Prompt 调优从一门玄学变成一门工程科学。

Q2.2 如何做好一个 RAG，怎么样让 RAG 更准确召回
RAG (Retrieval-Augmented Generation) 是当前解决 LLM 知识局限性和事实幻觉问题的最主流、最有效的架构。做好一个 RAG 系统的关键在于优化其生命周期的每一个环节，而提升召回准确率是重中之重。

Part 0: RAG 基本工作流程
Offline 数据索引
1. Loading Data: 数据质量
2. Chunking: 智能分块，语义分块，添加元数据
3. Embedding: 使用 Embedding Model 转成向量
4. Indexing: 通过向量索引到文本
Online 检索
1. User Query
2. Embed Query
3. Retrieve: 
4. Augment
5: Generate

RAG  解决传统 LLM 三大痛点：
- 减少幻觉：答案基于提供的资料，不再凭空编造
- 知识实时更新：只需更新知识库，LLM 就能回答最新的问题，无需重新训练模型
- 支持私有知识：可以连接到任何私有数据库，让 LLM 成为 “懂你公司业务”的专家，同时保证数据的私密性

Part 1: 如何做好一个 RAG 系统 (整体架构)
一个优秀的 RAG 系统，需要关注以下五个核心阶段：

数据准备与分块 (Data Preparation & Chunking)

源头质量：垃圾进，垃圾出。确保你的知识库数据是干净、准确、无重复的。

智能分块 (Intelligent Chunking)：这是基础。简单的固定大小分块会割裂语义。

策略：应采用 “语义分块” 或 “递归分块”，例如按段落、标题、句子或代码函数来切分，确保每个块（Chunk）都是一个有意义的独立单元。

元数据 (Metadata)：为每个块附加丰富的元数据（如来源文档、章节、创建日期），这对于后续的过滤和溯源至关重要。

向量化与索引 (Embedding & Indexing)

选择合适的 Embedding 模型：不是越大的模型越好。要选择与你的数据领域和查询类型最匹配的模型。可以参考 MTEB (Massive Text Embedding Benchmark) 排行榜。

构建索引：将向量化后的数据块存入专门的向量数据库（如 Pinecone, Weaviate, Milvus, Chroma），并建立高效的索引（如 HNSW）。

检索 (Retrieval) - 这是 RAG 的心脏

这个环节的质量直接决定了 RAG 的上限。基础的向量搜索只是起点，我们需要更精细的策略（详见 Part 2）。

增强与生成 (Augmentation & Generation)

构建上下文 Prompt：将被检索到的数据块（上下文）与原始用户问题，按照一个高效的模板组合成一个新的 Prompt。

选择合适的生成 LLM：负责生成答案的 LLM 需要有强大的语言理解和信息整合能力，能忠实于给定的上下文，并流畅地生成答案。

评估与迭代 (Evaluation & Iteration)

建立评估框架：使用 RAGAS, TruLens 等工具，从多个维度评估 RAG 系统的表现：

检索评估：召回率 (Recall)、精确率 (Precision)。

生成评估：答案的忠实度 (Faithfulness，即是否基于上下文)、答案的相关性 (Answer Relevance)。

持续对失败案例进行分析，反向优化上述四个环节。

Part 2: 怎么样让 RAG 更准确召回 (核心技术)
召回不准是 RAG 最常见的问题，通常表现为“答非所问”或“找不到信息”。以下是几种提升召回准确率的核心技术，通常会组合使用：

混合搜索 (Hybrid Search)

问题：单纯的向量搜索（语义搜索）可能对特定的关键词、术语、产品型号不敏感。

方案：将 向量搜索 与传统的 关键词搜索（如 BM25 算法） 结合起来。语义搜索负责理解意图，关键词搜索负责匹配专有名词。两者结合，取长补短，是目前最稳定、最有效的提升召回的手段之一。

查询转换 (Query Transformations)

问题：用户的原始问题可能过于口语化、简洁或包含多个子问题，直接用于检索效果不佳。

方案：在检索前，使用 LLM 本身来“重写”或“增强”用户的问题。

查询扩展 (Query Expansion)：生成多个同义或相关的查询语句，多路出击进行检索，然后合并结果。

子问题分解 (Sub-Query Decomposition)：将一个复杂问题（“对比A和B的优劣”）分解为多个原子问题（“A的优点是什么？”、“B的优点是什么？”），分别检索，再汇总给生成模型。

假设性问题生成 (Hypothetical Document Embeddings, HyDE)：让 LLM 先根据用户问题生成一个“理想的”答案文档，然后用这个虚构文档的向量去检索，往往能找到语义上更匹配的真实文档。

重排序 (Reranking)

问题：初步检索（召回阶段）为了速度，可能不够精准，返回的结果中，最相关的文档不一定排在第一位。

方案：采用 “召回 + 重排” 的两阶段策略。

召回 (Recall)：先用较快的方法（如混合搜索）从海量数据中召回一个较大的候选集（如 Top 20-50 个文档）。

重排 (Rerank)：然后使用一个更强大、更精密的重排模型（如 Cohere Rerank 或 Cross-Encoders）对这个小候选集进行打分和重新排序，选出最终最相关的 Top 3-5 个文档送给生成模型。

效果：这是以微小的延迟增加为代价，大幅提升最终上下文质量的“大杀器”。

优化索引结构 (Advanced Indexing)

多向量索引 (Multi-Vector Indexing)：为一个文档块创建多个向量，例如：一个向量代表其内容的摘要，另一个向量代表其完整内容。查询时可以先与摘要向量匹配，找到粗粒度的相关文档，再深入细节。

图索引 (Graph Indexing)：将知识库中的实体和关系构建成知识图谱。查询时，可以同时在向量空间和图谱中进行检索，处理涉及复杂关系的查询时效果更佳。

通过系统性地应用上述一种或多种技术，你可以将 RAG 系统的召回准确率提升到一个新的水平，从而让整个应用变得更加可靠和智能。



# Q3: 事务机制，隔离级别，如何实现事务；
	什么是事务，ACID
	RU, RC, RR, SR
	间隙锁，和记录锁的区别，使用场景
	
# 算法题：不重复的有序旋转数组，请判断某个值是否在数组中，如果存在则返回索引，否则返回 -1


# QA